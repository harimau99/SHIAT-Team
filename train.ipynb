{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from scipy import misc\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_flip(img, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        img = image.flip_axis(img, 1)\n",
    "    return img\n",
    "\n",
    "def random_brightness(img, limit=(-0.3, 0.3), u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n",
    "        img = alpha * img\n",
    "        img = np.clip(img, 0., 1.)\n",
    "    return img\n",
    "\n",
    "def random_augmentation(img):\n",
    "    img = random_brightness(img, limit=(-0.5, 0.5), u=0.5)\n",
    "    img = random_flip(img, u=0.3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs, augmented_count = 5):\n",
    "    features = []\n",
    "    for img in imgs:\n",
    "        image = misc.imresize(misc.imread(img), (50, 50))\n",
    "        features.append(feature.canny(image))\n",
    "        #features.append(image)\n",
    "        for i in range(augmented_count):\n",
    "            file_features = random_augmentation(image)\n",
    "            features.append(feature.canny(file_features))\n",
    "            #features.append(file_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len husein: 122\n",
      "len unknown: 347\n"
     ]
    }
   ],
   "source": [
    "husein = glob.glob('Husein/*')\n",
    "unknown = glob.glob('Unknown/*')\n",
    "print('len husein:', len(husein))\n",
    "print('len unknown:', len(unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive samples: 732\n"
     ]
    }
   ],
   "source": [
    "husein_features = extract_features(husein)\n",
    "print ('positive samples:', len(husein_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive samples: 2082\n"
     ]
    }
   ],
   "source": [
    "unknown_features = extract_features(unknown)\n",
    "print ('positive samples:', len(unknown_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((husein_features, unknown_features)).astype(np.float64)\n",
    "X = X.reshape([X.shape[0], -1])\n",
    "\n",
    "pca = PCA(n_components = 100).fit(X)\n",
    "scaled_X = pca.transform(X)\n",
    "\n",
    "y = np.hstack((np.ones(len(husein_features)), np.zeros(len(unknown_features))))\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.139049\tvalid-error:0.134991\n",
      "Multiple eval metrics have been passed: 'valid-error' will be used for early stopping.\n",
      "\n",
      "Will train until valid-error hasn't improved in 100 rounds.\n",
      "[5]\ttrain-error:0.124833\tvalid-error:0.12611\n",
      "[10]\ttrain-error:0.125722\tvalid-error:0.12611\n",
      "[15]\ttrain-error:0.11817\tvalid-error:0.124334\n",
      "[20]\ttrain-error:0.109285\tvalid-error:0.115453\n",
      "[25]\ttrain-error:0.112839\tvalid-error:0.117229\n",
      "[30]\ttrain-error:0.107952\tvalid-error:0.113677\n",
      "[35]\ttrain-error:0.108396\tvalid-error:0.115453\n",
      "[40]\ttrain-error:0.110173\tvalid-error:0.115453\n",
      "[45]\ttrain-error:0.112394\tvalid-error:0.117229\n",
      "[50]\ttrain-error:0.109729\tvalid-error:0.115453\n",
      "[55]\ttrain-error:0.108841\tvalid-error:0.115453\n",
      "[60]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[65]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[70]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[75]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[80]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[85]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[90]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[95]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[100]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[105]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[110]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[115]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[120]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "[125]\ttrain-error:0.107508\tvalid-error:0.113677\n",
      "Stopping. Best iteration:\n",
      "[29]\ttrain-error:0.108841\tvalid-error:0.113677\n",
      "\n",
      "1.407 Seconds to train xgb\n",
      "0.886323268206\n"
     ]
    }
   ],
   "source": [
    "params_xgd = {\n",
    "    'min_child_weight': 10.0,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 7,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.01,\n",
    "    'gamma': 0.65,\n",
    "    'num_boost_round' : 700\n",
    "    }\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, y_train)\n",
    "d_valid = xgb.DMatrix(X_test, y_test)\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "t=time.time()\n",
    "clf = xgb.train(params_xgd, d_train, 1600, watchlist, early_stopping_rounds=100,\n",
    "                maximize=False, verbose_eval=5)\n",
    "print(round(time.time()-t, 3), 'Seconds to train xgb')\n",
    "output = clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit)\n",
    "print(np.mean(y_test == np.around(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.127943\tvalid-error:0.134991\n",
      "Multiple eval metrics have been passed: 'valid-error' will be used for early stopping.\n",
      "\n",
      "Will train until valid-error hasn't improved in 100 rounds.\n",
      "[5]\ttrain-error:0.126166\tvalid-error:0.12611\n",
      "[10]\ttrain-error:0.124833\tvalid-error:0.12611\n",
      "[15]\ttrain-error:0.123056\tvalid-error:0.127886\n",
      "[20]\ttrain-error:0.119502\tvalid-error:0.124334\n",
      "[25]\ttrain-error:0.114171\tvalid-error:0.120782\n",
      "[30]\ttrain-error:0.113727\tvalid-error:0.120782\n",
      "[35]\ttrain-error:0.111506\tvalid-error:0.119005\n",
      "[40]\ttrain-error:0.110618\tvalid-error:0.115453\n",
      "[45]\ttrain-error:0.111506\tvalid-error:0.120782\n",
      "[50]\ttrain-error:0.112839\tvalid-error:0.120782\n",
      "[55]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[60]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[65]\ttrain-error:0.113727\tvalid-error:0.122558\n",
      "[70]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[75]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[80]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[85]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[90]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[95]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[100]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[105]\ttrain-error:0.113283\tvalid-error:0.120782\n",
      "[110]\ttrain-error:0.112839\tvalid-error:0.122558\n",
      "[115]\ttrain-error:0.112839\tvalid-error:0.122558\n",
      "[120]\ttrain-error:0.112839\tvalid-error:0.122558\n",
      "[125]\ttrain-error:0.112839\tvalid-error:0.122558\n",
      "[130]\ttrain-error:0.112839\tvalid-error:0.122558\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-error:0.113727\tvalid-error:0.115453\n",
      "\n",
      "1.576 Seconds to train xgb\n",
      "0.879218472469\n"
     ]
    }
   ],
   "source": [
    "params_xgd2 = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 4,\n",
    "    'max_delta_step': 1.8,\n",
    "    'min_child_weight': 6,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.07,\n",
    "    'gamma': 10,\n",
    "    'reg_alpha':8,\n",
    "    'reg_lambda':1.3\n",
    "    }\n",
    "t=time.time()\n",
    "clf2 = xgb.train(params_xgd2, d_train, 1600, watchlist, early_stopping_rounds=100,\n",
    "                maximize=False, verbose_eval=5)\n",
    "print(round(time.time()-t, 3), 'Seconds to train xgb')\n",
    "output = clf2.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit)\n",
    "print(np.mean(y_test == np.around(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.134163\tvalid-error:0.131439\n",
      "Multiple eval metrics have been passed: 'valid-error' will be used for early stopping.\n",
      "\n",
      "Will train until valid-error hasn't improved in 100 rounds.\n",
      "[5]\ttrain-error:0.130164\tvalid-error:0.124334\n",
      "[10]\ttrain-error:0.130164\tvalid-error:0.124334\n",
      "[15]\ttrain-error:0.130609\tvalid-error:0.12611\n",
      "[20]\ttrain-error:0.125722\tvalid-error:0.124334\n",
      "[25]\ttrain-error:0.122612\tvalid-error:0.122558\n",
      "[30]\ttrain-error:0.11195\tvalid-error:0.115453\n",
      "[35]\ttrain-error:0.111506\tvalid-error:0.113677\n",
      "[40]\ttrain-error:0.111506\tvalid-error:0.115453\n",
      "[45]\ttrain-error:0.109285\tvalid-error:0.113677\n",
      "[50]\ttrain-error:0.107952\tvalid-error:0.113677\n",
      "[55]\ttrain-error:0.107952\tvalid-error:0.113677\n",
      "[60]\ttrain-error:0.107952\tvalid-error:0.115453\n",
      "[65]\ttrain-error:0.108396\tvalid-error:0.113677\n",
      "[70]\ttrain-error:0.108396\tvalid-error:0.117229\n",
      "[75]\ttrain-error:0.109285\tvalid-error:0.117229\n",
      "[80]\ttrain-error:0.109285\tvalid-error:0.117229\n",
      "[85]\ttrain-error:0.109285\tvalid-error:0.117229\n",
      "[90]\ttrain-error:0.109285\tvalid-error:0.117229\n",
      "[95]\ttrain-error:0.107952\tvalid-error:0.117229\n",
      "[100]\ttrain-error:0.107508\tvalid-error:0.115453\n",
      "[105]\ttrain-error:0.107508\tvalid-error:0.115453\n",
      "[110]\ttrain-error:0.107508\tvalid-error:0.115453\n",
      "[115]\ttrain-error:0.107508\tvalid-error:0.115453\n",
      "[120]\ttrain-error:0.107508\tvalid-error:0.115453\n",
      "[125]\ttrain-error:0.106619\tvalid-error:0.115453\n",
      "[130]\ttrain-error:0.106175\tvalid-error:0.115453\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-error:0.111506\tvalid-error:0.113677\n",
      "\n",
      "1.616 Seconds to train xgb\n",
      "0.879218472469\n"
     ]
    }
   ],
   "source": [
    "params_xgd3 = {\n",
    "    'min_child_weight': 10.0,\n",
    "    'objective': 'binary:logistic',\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.025,\n",
    "    'gamma': 0.65,\n",
    "    'num_boost_round' : 700\n",
    "    }\n",
    "\n",
    "t=time.time()\n",
    "clf3 = xgb.train(params_xgd3, d_train, 1600, watchlist, early_stopping_rounds=100,\n",
    "                maximize=False, verbose_eval=5)\n",
    "print(round(time.time()-t, 3), 'Seconds to train xgb')\n",
    "output = clf3.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit)\n",
    "print(np.mean(y_test == np.around(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pca.p', 'wb') as fopen:\n",
    "    pickle.dump(pca, fopen, protocol=2)\n",
    "with open('xgb.p', 'wb') as fopen:\n",
    "    pickle.dump(clf, fopen, protocol=2)\n",
    "with open('xgb2.p', 'wb') as fopen:\n",
    "    pickle.dump(clf2, fopen, protocol=2)\n",
    "with open('xgb3.p', 'wb') as fopen:\n",
    "    pickle.dump(clf3, fopen, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Unknown       0.87      1.00      0.93       416\n",
      "     Husein       0.99      0.57      0.72       147\n",
      "\n",
      "avg / total       0.90      0.89      0.88       563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, np.around(clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit)), target_names = ['Unknown', 'Husein']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Unknown       0.87      1.00      0.93       416\n",
      "     Husein       0.99      0.57      0.72       147\n",
      "\n",
      "avg / total       0.90      0.89      0.88       563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, np.around(clf.predict(xgb.DMatrix(X_test), ntree_limit=clf2.best_ntree_limit)), target_names = ['Unknown', 'Husein']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Unknown       0.86      0.99      0.92       416\n",
      "     Husein       0.96      0.56      0.71       147\n",
      "\n",
      "avg / total       0.89      0.88      0.87       563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, np.around(clf3.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit)), target_names = ['Unknown', 'Husein']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_T = np.vstack([clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit), clf2.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit),clf3.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Unknown       0.87      1.00      0.93       416\n",
      "     Husein       0.99      0.56      0.72       147\n",
      "\n",
      "avg / total       0.90      0.88      0.87       563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, np.around(hmean(out_T, axis=1)), target_names = ['Unknown', 'Husein']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(hmean(out_T, axis=1)).astype('int')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
